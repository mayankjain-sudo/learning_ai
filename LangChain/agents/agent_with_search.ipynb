{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadenv = dotenv.load_dotenv(dotenv_path=\"./.env\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ed6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI assistant. Think step by step before answering.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562aed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_history = ChatMessageHistory()\n",
    "\n",
    "# Create memory checkpointer for conversation history\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Create the agent with tools and memory\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "# Agent executor function for easy invocation\n",
    "def execute_agent(user_input: str, thread_id: str = \"default-session\"):\n",
    "    \"\"\"\n",
    "    Execute the agent with a user query.\n",
    "    \n",
    "    Args:\n",
    "        user_input: The user's question or command\n",
    "        thread_id: Session identifier for conversation continuity\n",
    "    \n",
    "    Returns:\n",
    "        The agent's response\n",
    "    \"\"\"\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [(\"user\", user_input)]},\n",
    "        {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "# Example usage\n",
    "result = execute_agent(\"What is the weather in San Francisco?\")\n",
    "print(result)\n",
    "\n",
    "# Multi-turn conversation example (uses same thread_id for history)\n",
    "result2 = execute_agent(\"What about New York?\", thread_id=\"default-session\")\n",
    "print(result2)\n",
    "\n",
    "## Stream agent responses for real-time output\n",
    "#def stream_agent(user_input: str, thread_id: str = \"default-session\"):\n",
    "#    \"\"\"\n",
    "#    Stream the agent's response in real-time.\n",
    "#    \n",
    "#    Args:\n",
    "#        user_input: The user's question or command\n",
    "#        thread_id: Session identifier for conversation continuity\n",
    "#    \"\"\"\n",
    "#    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "#    \n",
    "#    for chunk in agent.stream(\n",
    "#        {\"messages\": [(\"user\", user_input)]},\n",
    "#        {\"configurable\": {\"thread_id\": thread_id}},\n",
    "#        stream_mode=\"values\"\n",
    "#    ):\n",
    "#\n",
    "## Example streaming\n",
    "#stream_agent(\"Tell me about the Eiffel Tower\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_envpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
